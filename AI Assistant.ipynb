{"cells":[{"source":"Building an AI Assistant for Data Science with Multimodal Capabilities","metadata":{},"id":"d239c107-6848-4445-8166-e759bf7f8736","cell_type":"markdown"},{"source":"# Run this to install the latest version of the OpenAI package\n!pip install openai==1.33.0","metadata":{"executionCancelledAt":null,"executionTime":3632,"lastExecutedAt":1747263679123,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this to install the latest version of the OpenAI package\n!pip install openai==1.33.0","outputsMetadata":{"0":{"height":521,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"e54fd213-2621-42ae-94ae-bfd0f3402230","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting openai==1.33.0\n  Downloading openai-1.33.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (4.8.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.33.0) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (0.27.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (2.7.1)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (4.12.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.33.0) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.33.0) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.33.0) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.33.0) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.33.0) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.33.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.33.0) (2.18.2)\nDownloading openai-1.33.0-py3-none-any.whl (325 kB)\nInstalling collected packages: openai\n\u001b[33m  WARNING: The script openai is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed openai-1.33.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Import the os package\nimport os\n\n# Import the openai package\nimport openai\n\n# Import the pandas package with an alias\nimport pandas as pd","metadata":{"executionCancelledAt":null,"executionTime":2101,"lastExecutedAt":1747263693942,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the os package\nimport os\n\n# Import the openai package\nimport openai\n\n# Import the pandas package with an alias\nimport pandas as pd"},"id":"c4800650-5f9d-4cc8-a3a4-f5a81e53ef44","cell_type":"code","execution_count":2,"outputs":[]},{"source":"# Define an OpenAI client. Assign to client.\nclient = openai.OpenAI()","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1747263693996,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define an OpenAI client. Assign to client.\nclient = openai.OpenAI()"},"id":"2bdb5463-7586-4fec-bb70-d3527524d779","cell_type":"code","execution_count":3,"outputs":[]},{"source":"## Task 1: Upload the Arxiv Papers","metadata":{},"id":"712c314c-24d4-4af8-b678-7697dac54ae3","cell_type":"markdown"},{"source":"#Uploading the papers\npapers = pd.DataFrame({\n    \"filename\": [\n        \"2405.10313v1.pdf\",\n        \"2401.03428v1.pdf\",\n        \"2401.09395v2.pdf\",\n        \"2401.13142v3.pdf\",\n        \"2403.02164v2.pdf\",\n        \"2403.12107v1.pdf\",\n        \"2404.10731v1.pdf\",\n        \"2312.11562v5.pdf\",\n        \"2311.02462v2.pdf\",\n        \"2310.15274v1.pdf\"\n    ],\n    \"title\": [\n        \"How Far Are We From AGI?\",\n        \"EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS\",\n        \"CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions\",\n        \"Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse\",\n        \"Cognition is All You Need The Next Layer of AI Above Large Language Models\",\n        \"Scenarios for the Transition to AGI\",\n        \"What is Meant by AGI? On the Definition of Artificial General Intelligence\",\n        \"A Survey of Reasoning with Foundation Models\",\n        \"Levels of AGI: Operationalizing Progress on the Path to AGI\",\n        \"Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges\"\n    ]\n})\npapers[\"filename\"] = \"papers/\" + papers[\"filename\"]\npapers","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"quickFilterText":"","customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"747131d1-855c-4769-b24c-0929e5292b6d","nodeType":"const"}}}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"visualizeDataframe":false,"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"}},"id":"5591f007-4b68-4b2a-ab00-4289b2b498cf","cell_type":"code","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"filename","type":"string"},{"name":"title","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5,6,7,8,9],"filename":["papers/2405.10313v1.pdf","papers/2401.03428v1.pdf","papers/2401.09395v2.pdf","papers/2401.13142v3.pdf","papers/2403.02164v2.pdf","papers/2403.12107v1.pdf","papers/2404.10731v1.pdf","papers/2312.11562v5.pdf","papers/2311.02462v2.pdf","papers/2310.15274v1.pdf"],"title":["How Far Are We From AGI?","EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS","CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions","Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse","Cognition is All You Need The Next Layer of AI Above Large Language Models","Scenarios for the Transition to AGI","What is Meant by AGI? On the Definition of Artificial General Intelligence","A Survey of Reasoning with Foundation Models","Levels of AGI: Operationalizing Progress on the Path to AGI","Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges"]}},"total_rows":10,"truncation_type":null},"text/plain":"                  filename                                              title\n0  papers/2405.10313v1.pdf                           How Far Are We From AGI?\n1  papers/2401.03428v1.pdf  EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGE...\n2  papers/2401.09395v2.pdf  CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM...\n3  papers/2401.13142v3.pdf  Unsocial Intelligence: an Investigation of the...\n4  papers/2403.02164v2.pdf  Cognition is All You Need The Next Layer of AI...\n5  papers/2403.12107v1.pdf                Scenarios for the Transition to AGI\n6  papers/2404.10731v1.pdf  What is Meant by AGI? On the Definition of Art...\n7  papers/2312.11562v5.pdf       A Survey of Reasoning with Foundation Models\n8  papers/2311.02462v2.pdf  Levels of AGI: Operationalizing Progress on th...\n9  papers/2310.15274v1.pdf  Systematic AI Approach for AGI: Addressing Ali...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>papers/2405.10313v1.pdf</td>\n      <td>How Far Are We From AGI?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>papers/2401.03428v1.pdf</td>\n      <td>EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGE...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>papers/2401.09395v2.pdf</td>\n      <td>CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>papers/2401.13142v3.pdf</td>\n      <td>Unsocial Intelligence: an Investigation of the...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>papers/2403.02164v2.pdf</td>\n      <td>Cognition is All You Need The Next Layer of AI...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>papers/2403.12107v1.pdf</td>\n      <td>Scenarios for the Transition to AGI</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>papers/2404.10731v1.pdf</td>\n      <td>What is Meant by AGI? On the Definition of Art...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>papers/2312.11562v5.pdf</td>\n      <td>A Survey of Reasoning with Foundation Models</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>papers/2311.02462v2.pdf</td>\n      <td>Levels of AGI: Operationalizing Progress on th...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>papers/2310.15274v1.pdf</td>\n      <td>Systematic AI Approach for AGI: Addressing Ali...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":4}]},{"source":"# Run this\ndef upload_file_for_assistant(file_path): \n    uploaded_file = client.files.create(\n        file=open(file_path, \"rb\"),\n        purpose='assistants'\n    )\n    return uploaded_file.id","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1747263696628,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\ndef upload_file_for_assistant(file_path): \n    uploaded_file = client.files.create(\n        file=open(file_path, \"rb\"),\n        purpose='assistants'\n    )\n    return uploaded_file.id"},"id":"98bcae6e-3f54-4d0a-90ee-b33c1fd0894e","cell_type":"code","execution_count":5,"outputs":[]},{"source":" # Assigning to uploaded_file_ids.\nuploaded_file_ids = papers['filename'] \\\n    .apply(upload_file_for_assistant) \\\n    .to_list()\n\n# See the result\nuploaded_file_ids","metadata":{"executionCancelledAt":null,"executionTime":10048,"lastExecutedAt":1747263708034,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":" # Assigning to uploaded_file_ids.\nuploaded_file_ids = papers['filename'] \\\n    .apply(upload_file_for_assistant) \\\n    .to_list()\n\n# See the result\nuploaded_file_ids","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"9d23ffbc-e8dc-4d84-8255-08b55da66270","cell_type":"code","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":"['file-ReLGbUAEWYUv9WbcJoPfbh',\n 'file-BrK1q3rHRfCtS56H4heYqw',\n 'file-96p93rZqUexeNo92qGkCm2',\n 'file-2BmefRPou5kSBfYcHQ3Rkm',\n 'file-XAERfUYrvuJFrAGZcpr6C4',\n 'file-W9mKi8a8PsbdZbcMBfQ8K4',\n 'file-VbjkSCV33EwUxQM1zYu6ka',\n 'file-DcajDM2tVAYdPHknJF4Prp',\n 'file-SNaaEjUaVgCALLoF24AsRp',\n 'file-2K96i4uTgQ4MxpnfX7kBer']"},"metadata":{},"execution_count":6}]},{"source":"### Check that this worked\n\nView the files in your account at https://platform.openai.com/storage/files","metadata":{},"id":"3d5dcf62-5677-4a95-bf43-48ab0ee7fdc9","cell_type":"markdown"},{"source":"## Task 2: Add the Files to a Vector Store","metadata":{},"id":"7c3e7127-c030-46ed-8226-9662af92198e","cell_type":"markdown"},{"source":"# Create a vector store, associating the uploaded file IDs and naming it.\nvstore = client.beta.vector_stores.create(\n    file_ids = uploaded_file_ids,\n    name = \"agi_papers\"\n)\n\n# See the results\nvstore","metadata":{"executionCancelledAt":null,"executionTime":706,"lastExecutedAt":1747263708741,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a vector store, associating the uploaded file IDs and naming it.\nvstore = client.beta.vector_stores.create(\n    file_ids = uploaded_file_ids,\n    name = \"agi_papers\"\n)\n\n# See the results\nvstore"},"id":"4831a606-50c3-42be-9448-4ba44f49959a","cell_type":"code","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":"VectorStore(id='vs_682520dc81b48191970aee913002fe7b', created_at=1747263708, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=10, total=10), last_active_at=1747263708, metadata={}, name='agi_papers', object='vector_store', status='in_progress', usage_bytes=0, expires_after=None, expires_at=None)"},"metadata":{},"execution_count":7}]},{"source":"### Check that this worked\n\nView the vector stores in your account at https://platform.openai.com/storage/vector_stores","metadata":{},"id":"e7820b86-5729-423d-87e3-7fb8fff0bcb9","cell_type":"markdown"},{"source":"## Task 3: Create the Assistant","metadata":{},"id":"8ed36d72-f053-408b-bcbb-76b679d158a7","cell_type":"markdown"},{"source":"# Creating the Prompt\nassistant_prompt = \"\"\"\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n\nWhen explaining the contents of the papers, follow these guidelines:\n\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n\nThe main points and arguments presented.\nAny important methods or techniques used.\nKey results and findings.\nThe significance and implications of these findings.\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n\"\"\"","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1747263711887,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Creating the Prompt\nassistant_prompt = \"\"\"\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n\nWhen explaining the contents of the papers, follow these guidelines:\n\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n\nThe main points and arguments presented.\nAny important methods or techniques used.\nKey results and findings.\nThe significance and implications of these findings.\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n\"\"\""},"id":"b072f6b7-7071-4db5-b38c-30281739bc36","cell_type":"code","execution_count":8,"outputs":[]},{"source":"# Assuming vstore is an instance of a class that has an 'id' attribute, \n# we need to define vstore before using it in the assistant creation.\n\n# Create an instance of VectorStore\n#vstore = client.beta.vector_stores.create(name=\"MyVectorStore\")\n\n# Define the assistant. Assign to aggie.\naggie = client.beta.assistants.create(\n    name=\"Aggie\",\n    instructions=assistant_prompt,\n    model=\"gpt-4o\",  \n    tools=[{\"type\": \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n)\n\n# See the result\naggie","metadata":{"executionCancelledAt":null,"executionTime":712,"lastExecutedAt":1747263721487,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Assuming vstore is an instance of a class that has an 'id' attribute, \n# we need to define vstore before using it in the assistant creation.\n\n# Create an instance of VectorStore\n#vstore = client.beta.vector_stores.create(name=\"MyVectorStore\")\n\n# Define the assistant. Assign to aggie.\naggie = client.beta.assistants.create(\n    name=\"Aggie\",\n    instructions=assistant_prompt,\n    model=\"gpt-4o\",  \n    tools=[{\"type\": \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n)\n\n# See the result\naggie"},"id":"a9da4370-6f66-4fd1-b309-5c330949d5d6","cell_type":"code","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Assistant(id='asst_9n4UlaVexhipzSdlntUy2T55', created_at=1747263721, description=None, instructions=\"\\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\\n\\nWhen explaining the contents of the papers, follow these guidelines:\\n\\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\\n\\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\\n\\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\\n\\nThe main points and arguments presented.\\nAny important methods or techniques used.\\nKey results and findings.\\nThe significance and implications of these findings.\\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\\n\\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\\n\\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\\n\\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\\n\\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\\n\\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\\n\", metadata={}, model='gpt-4o', name='Aggie', object='assistant', tools=[FileSearchTool(type='file_search', file_search=FileSearch(max_num_results=None, ranking_options={'ranker': 'default_2024_08_21', 'score_threshold': 0.0}))], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_682520dc81b48191970aee913002fe7b'])), top_p=1.0, reasoning_effort=None)"},"metadata":{},"execution_count":9}]},{"source":"### Check that this worked\n\nView the assistants in your account at https://platform.openai.com/playground/assistants","metadata":{},"id":"6bc73e71-f1e8-49e8-93b9-633a07ca484f","cell_type":"markdown"},{"source":"## Task 4: Create a Conversation Thread","metadata":{},"id":"9137136e-ff49-484e-90f5-c3c498363600","cell_type":"markdown"},{"source":"# Create a thread object. Assign to conversation.\nconversation = client.beta.threads.create()\n\n# See the result\nconversation","metadata":{"executionCancelledAt":null,"executionTime":238,"lastExecutedAt":1747263729907,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a thread object. Assign to conversation.\nconversation = client.beta.threads.create()\n\n# See the result\nconversation"},"id":"21a7227c-61bd-4124-b7ec-da82d86e8a0a","cell_type":"code","execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Thread(id='thread_0QuqxXxHpnLGXcFtsrFXgFuw', created_at=1747263729, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"},"metadata":{},"execution_count":10}]},{"source":"# Add a user message to the conversation. Assign to msg_what_is_agi.\nmsg_what_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"What are the most common definitions of AGI?\"\n)\n\n# See the result\nmsg_what_is_agi","metadata":{"executionCancelledAt":null,"executionTime":345,"lastExecutedAt":1747263730907,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Add a user message to the conversation. Assign to msg_what_is_agi.\nmsg_what_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"What are the most common definitions of AGI?\"\n)\n\n# See the result\nmsg_what_is_agi"},"id":"df4be81f-6a97-4c24-8a0d-cdf1e6724e62","cell_type":"code","execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Message(id='msg_PmGbbnKjqXpWZYxddRRi80PU', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What are the most common definitions of AGI?'), type='text')], created_at=1747263730, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_0QuqxXxHpnLGXcFtsrFXgFuw')"},"metadata":{},"execution_count":11}]},{"source":"## Task 5: Run the assistant","metadata":{},"id":"62515241-431f-4c7c-9e38-7e4522553173","cell_type":"markdown"},{"source":"# Run this\nfrom typing_extensions import override\nfrom openai import AssistantEventHandler\n \n# First, we create a EventHandler class to define\n# how we want to handle the events in the response stream.\n \nclass EventHandler(AssistantEventHandler):    \n  @override\n  def on_text_created(self, text) -> None:\n    print(f\"\\nassistant > \", end=\"\", flush=True)\n      \n  @override\n  def on_text_delta(self, delta, snapshot):\n    print(delta.value, end=\"\", flush=True)\n      \n  def on_tool_call_created(self, tool_call):\n    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n  \n  def on_tool_call_delta(self, delta, snapshot):\n    if delta.type == 'code_interpreter':\n      if delta.code_interpreter.input:\n        print(delta.code_interpreter.input, end=\"\", flush=True)\n      if delta.code_interpreter.outputs:\n        print(f\"\\n\\noutput >\", flush=True)\n        for output in delta.code_interpreter.outputs:\n          if output.type == \"logs\":\n            print(f\"\\n{output.logs}\", flush=True)\n","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1747263737910,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\nfrom typing_extensions import override\nfrom openai import AssistantEventHandler\n \n# First, we create a EventHandler class to define\n# how we want to handle the events in the response stream.\n \nclass EventHandler(AssistantEventHandler):    \n  @override\n  def on_text_created(self, text) -> None:\n    print(f\"\\nassistant > \", end=\"\", flush=True)\n      \n  @override\n  def on_text_delta(self, delta, snapshot):\n    print(delta.value, end=\"\", flush=True)\n      \n  def on_tool_call_created(self, tool_call):\n    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n  \n  def on_tool_call_delta(self, delta, snapshot):\n    if delta.type == 'code_interpreter':\n      if delta.code_interpreter.input:\n        print(delta.code_interpreter.input, end=\"\", flush=True)\n      if delta.code_interpreter.outputs:\n        print(f\"\\n\\noutput >\", flush=True)\n        for output in delta.code_interpreter.outputs:\n          if output.type == \"logs\":\n            print(f\"\\n{output.logs}\", flush=True)\n"},"id":"934c5d08-00db-4a55-974d-06ca5d021b18","cell_type":"code","execution_count":12,"outputs":[]},{"source":"# Run this\ndef run_aggie():\n    with client.beta.threads.runs.stream(\n        thread_id=conversation.id,\n        assistant_id=aggie.id,\n        event_handler=EventHandler(),\n    ) as stream:\n        stream.until_done()","metadata":{"executionCancelledAt":null,"executionTime":8,"lastExecutedAt":1747263739280,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\ndef run_aggie():\n    with client.beta.threads.runs.stream(\n        thread_id=conversation.id,\n        assistant_id=aggie.id,\n        event_handler=EventHandler(),\n    ) as stream:\n        stream.until_done()","outputsMetadata":{"0":{"height":525,"type":"stream"}}},"id":"572a21fd-e075-4d1c-82c6-279530c8395f","cell_type":"code","execution_count":13,"outputs":[]},{"source":"# Run the assistant\nrun_aggie()","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"644251b4-3623-4104-9ca8-d23a156cc354","cell_type":"code","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"\nassistant > file_search\n\n\nassistant > The definitions of Artificial General Intelligence (AGI) vary widely, reflecting different focuses and assumptions in AI research. Here are some common definitions of AGI:\n\n1. **Human-Level Cognitive Tasks**: AGI is often defined as a machine capable of performing the cognitive tasks that humans can typically do, without necessarily requiring a physical embodiment【4:1†source】.\n\n2. **General Learning Abilities**: Another common definition of AGI is an AI that is not specialized for specific tasks but can learn to perform a wide range of tasks, similar to humans【4:2†source】.\n\n3. **Economically Valuable Work**: OpenAI defines AGI as highly autonomous systems that outperform humans in most economically valuable work. This definition emphasizes performance and economic impact rather than the processes behind intelligence【4:2†source】.\n\n4. **Flexibility and Generality**: Some definitions highlight the need for AGI to be flexible and general, capable of adapting to new tasks and situations with reliability comparable to human intelligence【4:1†source】【4:2†source】.\n\n5. **Capable of Complex Tasks**: Mustafa Suleyman and Michael Bhaskar introduce the concept of \"Artificial Capable Intelligence,\" focusing on AI systems that can perform complex, multi-step tasks that are valuable in real-world scenarios【4:19†source】.\n\n6. **Levels of AGI**: Google DeepMind's \"Levels of AGI\" framework categorizes AGI based on breadth (generality) and depth (performance), providing a nuanced view of AGI progression【4:6†source】.\n\nThese definitions underscore the diversity in understanding AGI, with emphasis ranging from practical capabilities to theoretical and philosophical considerations. Each definition reflects different priorities, such as economic viability, learning capabilities, and task flexibility, illustrating the multifaceted nature of designing and evaluating AGI systems."}]},{"source":"# Create another user message, adding it to the conversation. Assign to msg_how_close_is_agi.\nmsg_how_close_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"How Far Are We From AGI?\"\n)\n\n# See the result\nmsg_how_close_is_agi","metadata":{"executionCancelledAt":null,"executionTime":355,"lastExecutedAt":1747263775142,"lastExecutedByKernel":"2463f36f-2490-4a55-823a-8c9796a9a4d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create another user message, adding it to the conversation. Assign to msg_how_close_is_agi.\nmsg_how_close_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"How Far Are We From AGI?\"\n)\n\n# See the result\nmsg_how_close_is_agi"},"id":"2cf9ea40-5c90-4a47-a3d5-59e4f3d3fa74","cell_type":"code","execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Message(id='msg_pTaTkAvYU8pixxMl8RqT2Sbs', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='How Far Are We From AGI?'), type='text')], created_at=1747263774, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_0QuqxXxHpnLGXcFtsrFXgFuw')"},"metadata":{},"execution_count":15}]},{"source":"# Run the assistant\nrun_aggie()","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"39d1173c-a1f5-4ebc-be74-a66fa8b80959","cell_type":"code","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"\nassistant > file_search\n\n\nassistant > The question of how far we are from achieving Artificial General Intelligence (AGI) does not have a definitive answer, as opinions within the AI research community vary significantly:\n\n1. **Diverse Opinions from Experts**: A poll conducted at the ICLR 2024 \"How Far Are We From AGI\" workshop showcased a range of opinions among researchers. Approximately 37% predicted that it would take more than 20 years to achieve AGI, while others were more optimistic, suggesting it could be within a few decades【8:0†source】.\n\n2. **Technical and Philosophical Challenges**: Several hurdles remain in achieving AGI, including technical, ethical, and philosophical issues. Current AI systems often operate as \"black boxes\" with limited explainability and transparency, which is a significant barrier for AGI development【8:19†source】. Additionally, there are unresolved challenges in emulating human-like reasoning, ensuring AI safety, and aligning AI with human values【8:13†source】【8:19†source】.\n\n3. **Scaling and Resource Concerns**: The process of scaling AI models to achieve AGI is another area of focus. While increasing model size and training data has led to improvements, there are diminishing returns, and concerns about resource requirements are prominent【8:0†source】.\n\n4. **Concurrent Pathways to AGI**: Some researchers suggest that multiple pathways to AGI might exist, emphasizing the development of diverse digital intelligences that follow different routes and approaches【8:18†source】.\n\n5. **Long-Term Speculation and Research**: While the technical path towards AGI is fraught with complexities, the philosophical quest to redefine intelligence continues to inspire researchers. The timeline remains uncertain, with broader discussions emphasizing the responsible approach toward developing AGI【8:9†source】【8:11†source】.\n\nOverall, while significant advancements have been made in AI, achieving AGI involves overcoming substantial technical, ethical, and philosophical challenges, with timelines for its realization varying widely among experts【8:0†source】【8:7†source】."}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}