{"cells":[{"source":"Building an AI Assistant for Data Science with Multimodal Capabilities","metadata":{},"id":"d239c107-6848-4445-8166-e759bf7f8736","cell_type":"markdown"},{"source":"# Run this to install the latest version of the OpenAI package\n!pip install openai==1.33.0","metadata":{"executionCancelledAt":null,"executionTime":2961,"lastExecutedAt":1747262815293,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this to install the latest version of the OpenAI package\n!pip install openai==1.33.0","outputsMetadata":{"0":{"height":521,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"e54fd213-2621-42ae-94ae-bfd0f3402230","cell_type":"code","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: openai==1.33.0 in /home/repl/.local/lib/python3.10/site-packages (1.33.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (4.8.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.33.0) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (0.27.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (2.7.1)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.33.0) (4.12.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.33.0) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.33.0) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.33.0) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.33.0) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.33.0) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.33.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.33.0) (2.18.2)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Import the os package\nimport os\n\n# Import the openai package\nimport openai\n\n# Import the pandas package with an alias\nimport pandas as pd","metadata":{"executionCancelledAt":null,"executionTime":8,"lastExecutedAt":1747262824144,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the os package\nimport os\n\n# Import the openai package\nimport openai\n\n# Import the pandas package with an alias\nimport pandas as pd"},"id":"c4800650-5f9d-4cc8-a3a4-f5a81e53ef44","cell_type":"code","execution_count":38,"outputs":[]},{"source":"# Define an OpenAI client. Assign to client.\nclient = openai.OpenAI()","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1747262825861,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define an OpenAI client. Assign to client.\nclient = openai.OpenAI()"},"id":"2bdb5463-7586-4fec-bb70-d3527524d779","cell_type":"code","execution_count":39,"outputs":[]},{"source":"## Task 1: Upload the Arxiv Papers","metadata":{},"id":"712c314c-24d4-4af8-b678-7697dac54ae3","cell_type":"markdown"},{"source":"#Uploading the papers\npapers = pd.DataFrame({\n    \"filename\": [\n        \"2405.10313v1.pdf\",\n        \"2401.03428v1.pdf\",\n        \"2401.09395v2.pdf\",\n        \"2401.13142v3.pdf\",\n        \"2403.02164v2.pdf\",\n        \"2403.12107v1.pdf\",\n        \"2404.10731v1.pdf\",\n        \"2312.11562v5.pdf\",\n        \"2311.02462v2.pdf\",\n        \"2310.15274v1.pdf\"\n    ],\n    \"title\": [\n        \"How Far Are We From AGI?\",\n        \"EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS\",\n        \"CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions\",\n        \"Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse\",\n        \"Cognition is All You Need The Next Layer of AI Above Large Language Models\",\n        \"Scenarios for the Transition to AGI\",\n        \"What is Meant by AGI? On the Definition of Artificial General Intelligence\",\n        \"A Survey of Reasoning with Foundation Models\",\n        \"Levels of AGI: Operationalizing Progress on the Path to AGI\",\n        \"Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges\"\n    ]\n})\npapers[\"filename\"] = \"papers/\" + papers[\"filename\"]\npapers","metadata":{"executionCancelledAt":null,"executionTime":22,"lastExecutedAt":1747262834195,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Uploading the papers\npapers = pd.DataFrame({\n    \"filename\": [\n        \"2405.10313v1.pdf\",\n        \"2401.03428v1.pdf\",\n        \"2401.09395v2.pdf\",\n        \"2401.13142v3.pdf\",\n        \"2403.02164v2.pdf\",\n        \"2403.12107v1.pdf\",\n        \"2404.10731v1.pdf\",\n        \"2312.11562v5.pdf\",\n        \"2311.02462v2.pdf\",\n        \"2310.15274v1.pdf\"\n    ],\n    \"title\": [\n        \"How Far Are We From AGI?\",\n        \"EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS\",\n        \"CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions\",\n        \"Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse\",\n        \"Cognition is All You Need The Next Layer of AI Above Large Language Models\",\n        \"Scenarios for the Transition to AGI\",\n        \"What is Meant by AGI? On the Definition of Artificial General Intelligence\",\n        \"A Survey of Reasoning with Foundation Models\",\n        \"Levels of AGI: Operationalizing Progress on the Path to AGI\",\n        \"Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges\"\n    ]\n})\npapers[\"filename\"] = \"papers/\" + papers[\"filename\"]\npapers","outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"quickFilterText":"","customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"747131d1-855c-4769-b24c-0929e5292b6d","nodeType":"const"}}}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"visualizeDataframe":false,"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"}},"id":"5591f007-4b68-4b2a-ab00-4289b2b498cf","cell_type":"code","execution_count":40,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"filename","type":"string"},{"name":"title","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5,6,7,8,9],"filename":["papers/2405.10313v1.pdf","papers/2401.03428v1.pdf","papers/2401.09395v2.pdf","papers/2401.13142v3.pdf","papers/2403.02164v2.pdf","papers/2403.12107v1.pdf","papers/2404.10731v1.pdf","papers/2312.11562v5.pdf","papers/2311.02462v2.pdf","papers/2310.15274v1.pdf"],"title":["How Far Are We From AGI?","EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS","CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions","Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse","Cognition is All You Need The Next Layer of AI Above Large Language Models","Scenarios for the Transition to AGI","What is Meant by AGI? On the Definition of Artificial General Intelligence","A Survey of Reasoning with Foundation Models","Levels of AGI: Operationalizing Progress on the Path to AGI","Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges"]}},"total_rows":10,"truncation_type":null},"text/plain":"                  filename                                              title\n0  papers/2405.10313v1.pdf                           How Far Are We From AGI?\n1  papers/2401.03428v1.pdf  EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGE...\n2  papers/2401.09395v2.pdf  CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM...\n3  papers/2401.13142v3.pdf  Unsocial Intelligence: an Investigation of the...\n4  papers/2403.02164v2.pdf  Cognition is All You Need The Next Layer of AI...\n5  papers/2403.12107v1.pdf                Scenarios for the Transition to AGI\n6  papers/2404.10731v1.pdf  What is Meant by AGI? On the Definition of Art...\n7  papers/2312.11562v5.pdf       A Survey of Reasoning with Foundation Models\n8  papers/2311.02462v2.pdf  Levels of AGI: Operationalizing Progress on th...\n9  papers/2310.15274v1.pdf  Systematic AI Approach for AGI: Addressing Ali...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>papers/2405.10313v1.pdf</td>\n      <td>How Far Are We From AGI?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>papers/2401.03428v1.pdf</td>\n      <td>EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGE...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>papers/2401.09395v2.pdf</td>\n      <td>CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>papers/2401.13142v3.pdf</td>\n      <td>Unsocial Intelligence: an Investigation of the...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>papers/2403.02164v2.pdf</td>\n      <td>Cognition is All You Need The Next Layer of AI...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>papers/2403.12107v1.pdf</td>\n      <td>Scenarios for the Transition to AGI</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>papers/2404.10731v1.pdf</td>\n      <td>What is Meant by AGI? On the Definition of Art...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>papers/2312.11562v5.pdf</td>\n      <td>A Survey of Reasoning with Foundation Models</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>papers/2311.02462v2.pdf</td>\n      <td>Levels of AGI: Operationalizing Progress on th...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>papers/2310.15274v1.pdf</td>\n      <td>Systematic AI Approach for AGI: Addressing Ali...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":40}]},{"source":"# Run this\ndef upload_file_for_assistant(file_path): \n    uploaded_file = client.files.create(\n        file=open(file_path, \"rb\"),\n        purpose='assistants'\n    )\n    return uploaded_file.id","metadata":{"executionCancelledAt":null,"executionTime":8,"lastExecutedAt":1747262838463,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\ndef upload_file_for_assistant(file_path): \n    uploaded_file = client.files.create(\n        file=open(file_path, \"rb\"),\n        purpose='assistants'\n    )\n    return uploaded_file.id"},"id":"98bcae6e-3f54-4d0a-90ee-b33c1fd0894e","cell_type":"code","execution_count":41,"outputs":[]},{"source":" # Assigning to uploaded_file_ids.\nuploaded_file_ids = papers['filename'] \\\n    .apply(upload_file_for_assistant) \\\n    .to_list()\n\n# See the result\nuploaded_file_ids","metadata":{"executionCancelledAt":null,"executionTime":8208,"lastExecutedAt":1747262849065,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":" # Assigning to uploaded_file_ids.\nuploaded_file_ids = papers['filename'] \\\n    .apply(upload_file_for_assistant) \\\n    .to_list()\n\n# See the result\nuploaded_file_ids","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"9d23ffbc-e8dc-4d84-8255-08b55da66270","cell_type":"code","execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":"['file-7L78hFS7xtDz1E5kHK4H1N',\n 'file-9siuNRmpWHjRq8ymb42JRR',\n 'file-1BtKqAeDmskD83yDwcrhUc',\n 'file-2wR5hwgQQifHRq3GJCYQQ9',\n 'file-PugmuBhxnaciTTJqbYY5VL',\n 'file-9krCGSbDsFjdd8GJx3T2J3',\n 'file-4FJCT34Dhqsy64bUJzZj9d',\n 'file-8aj8dVjeTRNqrpMDBZxFNj',\n 'file-DijBFDY1e4bzubqqs3viHc',\n 'file-FHr4GY2hP5e1mWMxkCjcPY']"},"metadata":{},"execution_count":42}]},{"source":"### Check that this worked\n\nView the files in your account at https://platform.openai.com/storage/files","metadata":{},"id":"3d5dcf62-5677-4a95-bf43-48ab0ee7fdc9","cell_type":"markdown"},{"source":"## Task 2: Add the Files to a Vector Store","metadata":{},"id":"7c3e7127-c030-46ed-8226-9662af92198e","cell_type":"markdown"},{"source":"# Create a vector store, associating the uploaded file IDs and naming it.\nvstore = client.beta.vector_stores.create(\n    file_ids = uploaded_file_ids,\n    name = \"agi_papers\"\n)\n\n# See the results\nvstore","metadata":{"executionCancelledAt":null,"executionTime":1039,"lastExecutedAt":1747262893401,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a vector store, associating the uploaded file IDs and naming it.\nvstore = client.beta.vector_stores.create(\n    file_ids = uploaded_file_ids,\n    name = \"agi_papers\"\n)\n\n# See the results\nvstore"},"id":"4831a606-50c3-42be-9448-4ba44f49959a","cell_type":"code","execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":"VectorStore(id='vs_68251dacf9d4819182211b8e34240239', created_at=1747262892, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=10, total=10), last_active_at=1747262892, metadata={}, name='agi_papers', object='vector_store', status='in_progress', usage_bytes=0, expires_after=None, expires_at=None)"},"metadata":{},"execution_count":43}]},{"source":"### Check that this worked\n\nView the vector stores in your account at https://platform.openai.com/storage/vector_stores","metadata":{},"id":"e7820b86-5729-423d-87e3-7fb8fff0bcb9","cell_type":"markdown"},{"source":"## Task 3: Create the Assistant","metadata":{},"id":"8ed36d72-f053-408b-bcbb-76b679d158a7","cell_type":"markdown"},{"source":"# Creating the Prompt\nassistant_prompt = \"\"\"\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n\nWhen explaining the contents of the papers, follow these guidelines:\n\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n\nThe main points and arguments presented.\nAny important methods or techniques used.\nKey results and findings.\nThe significance and implications of these findings.\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n\"\"\"","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1747262917786,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Creating the Prompt\nassistant_prompt = \"\"\"\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n\nWhen explaining the contents of the papers, follow these guidelines:\n\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n\nThe main points and arguments presented.\nAny important methods or techniques used.\nKey results and findings.\nThe significance and implications of these findings.\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n\"\"\""},"id":"b072f6b7-7071-4db5-b38c-30281739bc36","cell_type":"code","execution_count":44,"outputs":[]},{"source":"# Assuming vstore is an instance of a class that has an 'id' attribute, \n# we need to define vstore before using it in the assistant creation.\n\n# Create an instance of VectorStore\nvstore = client.beta.vector_stores.create(name=\"MyVectorStore\")\n\n# Define the assistant. Assign to aggie.\naggie = client.beta.assistants.create(\n    name=\"Aggie\",\n    instructions=assistant_prompt,\n    model=\"gpt-4o\",  \n    tools=[{\"type\": \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n)\n\n# See the result\naggie","metadata":{"executionCancelledAt":null,"executionTime":2127,"lastExecutedAt":1747262924754,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Assuming vstore is an instance of a class that has an 'id' attribute, \n# we need to define vstore before using it in the assistant creation.\n\n# Create an instance of VectorStore\nvstore = client.beta.vector_stores.create(name=\"MyVectorStore\")\n\n# Define the assistant. Assign to aggie.\naggie = client.beta.assistants.create(\n    name=\"Aggie\",\n    instructions=assistant_prompt,\n    model=\"gpt-4o\",  \n    tools=[{\"type\": \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n)\n\n# See the result\naggie"},"id":"a9da4370-6f66-4fd1-b309-5c330949d5d6","cell_type":"code","execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Assistant(id='asst_DSh9dfVQJkEcU8hKUYWST6ME', created_at=1747262924, description=None, instructions=\"\\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\\n\\nWhen explaining the contents of the papers, follow these guidelines:\\n\\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\\n\\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\\n\\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\\n\\nThe main points and arguments presented.\\nAny important methods or techniques used.\\nKey results and findings.\\nThe significance and implications of these findings.\\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\\n\\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\\n\\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\\n\\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\\n\\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\\n\\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\\n\", metadata={}, model='gpt-4o', name='Aggie', object='assistant', tools=[FileSearchTool(type='file_search', file_search=FileSearch(max_num_results=None, ranking_options={'ranker': 'default_2024_08_21', 'score_threshold': 0.0}))], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_68251dcbf76c819199f8c7b437ac75f2'])), top_p=1.0, reasoning_effort=None)"},"metadata":{},"execution_count":45}]},{"source":"### Check that this worked\n\nView the assistants in your account at https://platform.openai.com/playground/assistants","metadata":{},"id":"6bc73e71-f1e8-49e8-93b9-633a07ca484f","cell_type":"markdown"},{"source":"## Task 4: Create a Conversation Thread","metadata":{},"id":"9137136e-ff49-484e-90f5-c3c498363600","cell_type":"markdown"},{"source":"# Create a thread object. Assign to conversation.\nconversation = client.beta.threads.create()\n\n# See the result\nconversation","metadata":{"executionCancelledAt":null,"executionTime":256,"lastExecutedAt":1747262950150,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a thread object. Assign to conversation.\nconversation = client.beta.threads.create()\n\n# See the result\nconversation"},"id":"21a7227c-61bd-4124-b7ec-da82d86e8a0a","cell_type":"code","execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Thread(id='thread_iq5oZ03OBmMGbfQP4X12cD0L', created_at=1747262949, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"},"metadata":{},"execution_count":46}]},{"source":"# Add a user message to the conversation. Assign to msg_what_is_agi.\nmsg_what_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"What are the most common definitions of AGI?\"\n)\n\n# See the result\nmsg_what_is_agi","metadata":{"executionCancelledAt":null,"executionTime":401,"lastExecutedAt":1747262971459,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Add a user message to the conversation. Assign to msg_what_is_agi.\nmsg_what_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"What are the most common definitions of AGI?\"\n)\n\n# See the result\nmsg_what_is_agi"},"id":"df4be81f-6a97-4c24-8a0d-cdf1e6724e62","cell_type":"code","execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Message(id='msg_KwdPgnHQFJ6VkOaICHzIuS2k', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What are the most common definitions of AGI?'), type='text')], created_at=1747262971, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_iq5oZ03OBmMGbfQP4X12cD0L')"},"metadata":{},"execution_count":47}]},{"source":"## Task 5: Run the assistant","metadata":{},"id":"62515241-431f-4c7c-9e38-7e4522553173","cell_type":"markdown"},{"source":"# Run this\nfrom typing_extensions import override\nfrom openai import AssistantEventHandler\n \n# First, we create a EventHandler class to define\n# how we want to handle the events in the response stream.\n \nclass EventHandler(AssistantEventHandler):    \n  @override\n  def on_text_created(self, text) -> None:\n    print(f\"\\nassistant > \", end=\"\", flush=True)\n      \n  @override\n  def on_text_delta(self, delta, snapshot):\n    print(delta.value, end=\"\", flush=True)\n      \n  def on_tool_call_created(self, tool_call):\n    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n  \n  def on_tool_call_delta(self, delta, snapshot):\n    if delta.type == 'code_interpreter':\n      if delta.code_interpreter.input:\n        print(delta.code_interpreter.input, end=\"\", flush=True)\n      if delta.code_interpreter.outputs:\n        print(f\"\\n\\noutput >\", flush=True)\n        for output in delta.code_interpreter.outputs:\n          if output.type == \"logs\":\n            print(f\"\\n{output.logs}\", flush=True)\n","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1747262979180,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\nfrom typing_extensions import override\nfrom openai import AssistantEventHandler\n \n# First, we create a EventHandler class to define\n# how we want to handle the events in the response stream.\n \nclass EventHandler(AssistantEventHandler):    \n  @override\n  def on_text_created(self, text) -> None:\n    print(f\"\\nassistant > \", end=\"\", flush=True)\n      \n  @override\n  def on_text_delta(self, delta, snapshot):\n    print(delta.value, end=\"\", flush=True)\n      \n  def on_tool_call_created(self, tool_call):\n    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n  \n  def on_tool_call_delta(self, delta, snapshot):\n    if delta.type == 'code_interpreter':\n      if delta.code_interpreter.input:\n        print(delta.code_interpreter.input, end=\"\", flush=True)\n      if delta.code_interpreter.outputs:\n        print(f\"\\n\\noutput >\", flush=True)\n        for output in delta.code_interpreter.outputs:\n          if output.type == \"logs\":\n            print(f\"\\n{output.logs}\", flush=True)\n"},"id":"934c5d08-00db-4a55-974d-06ca5d021b18","cell_type":"code","execution_count":48,"outputs":[]},{"source":"# Run this\ndef run_aggie():\n    with client.beta.threads.runs.stream(\n        thread_id=conversation.id,\n        assistant_id=aggie.id,\n        event_handler=EventHandler(),\n    ) as stream:\n        stream.until_done()","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1747262986995,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\ndef run_aggie():\n    with client.beta.threads.runs.stream(\n        thread_id=conversation.id,\n        assistant_id=aggie.id,\n        event_handler=EventHandler(),\n    ) as stream:\n        stream.until_done()","outputsMetadata":{"0":{"height":525,"type":"stream"}}},"id":"572a21fd-e075-4d1c-82c6-279530c8395f","cell_type":"code","execution_count":49,"outputs":[]},{"source":"# Run the assistant\nrun_aggie()","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":584,"type":"stream"}}},"id":"644251b4-3623-4104-9ca8-d23a156cc354","cell_type":"code","execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":"\nassistant > file_search\n\n\nassistant > It seems that the uploaded documents do not contain explicit information on the common definitions of AGI. However, I can provide an overview based on general knowledge.\n\nArtificial General Intelligence (AGI) is commonly defined as a form of artificial intelligence that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks at a level comparable to or exceeding that of humans. AGI is distinguished from narrow AI, which is designed to excel at specific tasks but lacks the capability to generalize knowledge to new contexts or tasks.\n\nHere are some common elements found in definitions of AGI:\n\n1. **Generalization**: The capacity to transfer knowledge and skills across different domains, enabling the AGI system to apply learned information to novel situations.\n\n2. **Autonomy**: The ability to operate without human intervention, making decisions and solving problems independently.\n\n3. **Adaptability**: The capability to adapt to new environments and challenges by learning from experience and adjusting strategies as needed.\n\n4. **Human-like Performance**: Achieving or surpassing human cognitive abilities in a wide variety of areas, including reasoning, problem-solving, and understanding natural language.\n\n5. **Self-improvement**: The potential to enhance its own performance over time through learning and self-modification.\n\nThese definitions often emphasize the breadth and depth of cognitive capabilities required for AGI, contrasting with the task-specific nature of narrow AI. If you have any specific articles or sections you would like me to explore for a deeper understanding, feel free to guide me further!"}]},{"source":"# Create another user message, adding it to the conversation. Assign to msg_how_close_is_agi.\nmsg_how_close_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"How Far Are We From AGI?\"\n)\n\n# See the result\nmsg_how_close_is_agi","metadata":{"executionCancelledAt":null,"executionTime":584,"lastExecutedAt":1747263142361,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create another user message, adding it to the conversation. Assign to msg_how_close_is_agi.\nmsg_how_close_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"How Far Are We From AGI?\"\n)\n\n# See the result\nmsg_how_close_is_agi"},"id":"2cf9ea40-5c90-4a47-a3d5-59e4f3d3fa74","cell_type":"code","execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Message(id='msg_z903Pu4f8fJ1t0jMVstbHstK', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='How Far Are We From AGI?'), type='text')], created_at=1747263142, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_iq5oZ03OBmMGbfQP4X12cD0L')"},"metadata":{},"execution_count":53}]},{"source":"# Run the assistant\nrun_aggie()","metadata":{"executionCancelledAt":null,"executionTime":22883,"lastExecutedAt":1747263167686,"lastExecutedByKernel":"5b3dda71-c20a-4b48-9319-0f48c9b9218f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run the assistant\nrun_aggie()","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"39d1173c-a1f5-4ebc-be74-a66fa8b80959","cell_type":"code","execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":"\nassistant > file_search\n\n\nassistant > The uploaded documents do not seem to address the question of how far we are from achieving AGI. Nevertheless, I can provide insights based on the current understanding and discussions in the AI community.\n\nThe progress towards AGI is difficult to quantify due to a variety of scientific, technical, and philosophical challenges. Here are some considerations:\n\n1. **Current AI Landscape**: While AI has made impressive advances, these systems usually excel in specific tasks rather than generalizing across different domains. This underscores the distinction between narrow AI and AGI.\n\n2. **Ongoing Research**: Researchers are actively exploring various paths to AGI, including improving machine learning algorithms, understanding human cognition, and fostering machine learning techniques that enable better generalization.\n\n3. **Key Obstacles**: \n   - Replicating the complexity and adaptability of human cognitive processes.\n   - Ensuring machines can learn and adapt in real-time across diverse environments.\n   - Addressing ethical and safety concerns which become more pronounced as AI capabilities expand.\n\n4. **Timeframe Speculation**: There is no consensus on the timeline for achieving AGI. Projections range from a few decades to more than a century, or even doubts about its feasibility within current technological paradigms.\n\n5. **Implications**: The advent of AGI would bring transformative impacts on society, economics, and science. However, it also raises questions about control, safety, and the future role of humans in a world with potentially superintelligent machines.\n\nThe pursuit of AGI continues to be an exciting and challenging frontier in AI research. The journey involves not only technological advancements but also significant philosophical and ethical deliberations. If you have specific papers or discussions you want to focus on, feel free to direct me to those!"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}